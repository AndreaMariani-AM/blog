<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>GenStud</title>
        <link>https://genstud.netlify.app/</link>
        <description>Recent content on GenStud</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Mon, 05 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://genstud.netlify.app/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Simple Linear Regression and Polynomial Linear Regression</title>
        <link>https://genstud.netlify.app/p/simple-linear-regression-and-polynomial-linear-regression/</link>
        <pubDate>Mon, 05 Apr 2021 00:00:00 +0000</pubDate>
        
        <guid>https://genstud.netlify.app/p/simple-linear-regression-and-polynomial-linear-regression/</guid>
        <description>&lt;img src="https://genstud.netlify.app/p/simple-linear-regression-and-polynomial-linear-regression/pexels-eberhard-grossgasteiger-2088205.jpg" alt="Featured image of post Simple Linear Regression and Polynomial Linear Regression" /&gt;
&lt;script src=&#34;https://genstud.netlify.app/p/simple-linear-regression-and-polynomial-linear-regression/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In this post, we’ll talk about &lt;strong&gt;Simple Linear Regression&lt;/strong&gt; and &lt;strong&gt;Polynomial Linear Regression&lt;/strong&gt;. These two represent the backbone for linear and continuous regressions.&lt;/p&gt;
&lt;p&gt;There’s also &lt;strong&gt;Multiple Linear Regression&lt;/strong&gt; but it requires a small chat about model building, so it’ll be the content for a future post.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2VTYuHaL_sk&#34;&gt;First things first&lt;/a&gt;, let’s dive deep into what is Regression. Regression can be defined as a set of statistical processes that are trying to estimate the relationship between a dependent variable and one or more independent variables, creating a model that best fits the data.&lt;/p&gt;
&lt;p&gt;We’ll discuss more about what “best fit” means in a moment.&lt;/p&gt;
&lt;p&gt;Today, it’s often used as a way to predict the value of a dependent variable, given an independent variable.&lt;/p&gt;
&lt;p&gt;We can roughly divide Regression into Linear and Non-Linear Regression, and today we’ll focus on the linear (and continuous) ones.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1 x_i + \epsilon_i \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the model that represents a Simple Linear Regression and it’s a straight line that fits the data, where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the dependent variable, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is the independent variable, and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; are regression coefficients that measure the relationship between &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; .&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is a constant and represents where the line crosses the vertical axis, while &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; represents the slope of the line.
&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; is a disturbance error or error variable that helps model the relationship between &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; adding an unobservable “noise”.&lt;/p&gt;
&lt;p&gt;When we talk about &lt;em&gt;model that best fits the data&lt;/em&gt; we’re referring to the way the algorithm for Linear Regression builds the model. In other non-scientific words, given data points in a scatterplot, what is the line that best represents the data or best adapts to the data and how can we obtain it?&lt;/p&gt;
&lt;p&gt;There are all different kinds of methods for data fitting, and for Linear Regression the Least Squares method represents the standard approach.&lt;/p&gt;
&lt;p&gt;Basically, it draws an &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; number of lines that fits the data (aka goes through them), and for each line, it calculates &lt;strong&gt;the sum of squared residuals&lt;/strong&gt; where the residual is the difference between the observed values &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and the fitted value &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}\)&lt;/span&gt; that’s provided by the model.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \sum\limits_{i=1}^{n}(y_i – \hat{y}_1)^2 = min \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Every time, the algorithm tries to minimize this &lt;code&gt;sum&lt;/code&gt; and it stops when it’s no longer able to minimize it and that’s the model or the line that best fits the data.&lt;/p&gt;
&lt;p&gt;Before building a Linear Regression Model, some assumptions need checking.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Linearity&lt;/li&gt;
&lt;li&gt;Homoscedasticity&lt;/li&gt;
&lt;li&gt;Multivariate Normality&lt;/li&gt;
&lt;li&gt;Independence of Errors&lt;/li&gt;
&lt;li&gt;Lack of Multicollinearity&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We won’t talk about this ’cause there’s no time and I’m getting tired of typing on the keyboard, and plus we still gotta see how to build a model in R. And oh gosh, the Polynomial Regression, we need to check out that one too, almost forgot. Gotta move here, chop chop mf.&lt;/p&gt;
&lt;p&gt;Let’s see how we can build a simple Linear Regression Model. Dataset used are very small and just for article’s sake.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Trying to predict the Salary based on Years of Experience
regressor = lm(formula = Salary ~ YearsExperience,
               data = training_set)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can call &lt;code&gt;summary(regressor)&lt;/code&gt; to look at coefficients.&lt;/p&gt;
&lt;p&gt;Now let’s visualize the Regressor, where the &lt;code&gt;blue&lt;/code&gt; line represents our regressor and the &lt;code&gt;red&lt;/code&gt; points
represent datapoints.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_training &amp;lt;- ggplot() +
  geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
             colour = &amp;#39;red&amp;#39;) +
  geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
            colour = &amp;#39;blue&amp;#39;) +
  ggtitle(&amp;#39;Salary vs Experience (Training set)&amp;#39;) +
  xlab(&amp;#39;Years of experience&amp;#39;) +
  ylab(&amp;#39;Salary&amp;#39;)

plot_test &amp;lt;- ggplot() +
  geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
             colour = &amp;#39;red&amp;#39;) +
  geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
            colour = &amp;#39;blue&amp;#39;) +
  ggtitle(&amp;#39;Salary vs Experience (Test set)&amp;#39;) +
  xlab(&amp;#39;Years of experience&amp;#39;) +
  ylab(&amp;#39;Salary&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://genstud.netlify.app/p/simple-linear-regression-and-polynomial-linear-regression/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok now let’s talk about Polynomial Linear Regression&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1 x_i + \beta_2 x_1^{2} + \cdots + \beta_n x_1^{n} + \epsilon_i \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s address the elephant in the room, how’s this even linear? Well, Although it fits a nonlinear model to the data, as far as we’re concerned, as a statistical estimation problem it is linear, in the sense that the regression function is linear in the unknown parameters that are estimated from the data. For this reason, it’s also considered a special case of Multiple Linear Regression.&lt;/p&gt;
&lt;p&gt;Confusing much? We’ll circle back to this when talking Multiple Linear Regression.&lt;/p&gt;
&lt;p&gt;To explain this concept in other words, we can say that a Polynomial Regression Model is composed of one independent variable and additional independent variables that are polynomial terms of the first independent variable.&lt;/p&gt;
&lt;p&gt;Let’s see what it looks like. We’ll build both a Linear Regressor and Polynomial Regressor for the same dataset to compare them and see how they are able to predict values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Simple Linear Regressor Model
lin_reg &amp;lt;- lm(formula = Salary ~ Level,
              data = dataset1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Polynomial Regressor Model
poly_reg &amp;lt;- lm(formula = Salary ~ .,
               data = dataset2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s plot them and see how they behaves&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_lin &amp;lt;- dataset1 %&amp;gt;%
  ggplot() +
  geom_point(mapping = aes(x = Level, y = Salary), color = &amp;quot;red&amp;quot;) +
  geom_line(mapping = aes(x = Level, y = predict(lin_reg, newdata = dataset1)), color = &amp;quot;blue&amp;quot;) +
  ggtitle(&amp;quot;linear Regressor&amp;quot;) +
  xlab(&amp;quot;Level&amp;quot;) +
  ylab(&amp;quot;Salary&amp;quot;)

plot_poly &amp;lt;- dataset2 %&amp;gt;%
  ggplot() +
  geom_point(mapping = aes(x = Level, y = Salary), color = &amp;quot;red&amp;quot;) +
  geom_line(mapping = aes(x = Level, y = predict(poly_reg, newdata = dataset2)), color = &amp;quot;blue&amp;quot;) +
  ggtitle(&amp;quot;Polynomial Regressor&amp;quot;) +
  xlab(&amp;quot;Level&amp;quot;) +
  ylab(&amp;quot;Salary&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://genstud.netlify.app/p/simple-linear-regression-and-polynomial-linear-regression/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That was it, hope you enjoyed that.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;carbon.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Carbon&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
        <item>
        <title>Data Preprocessing for Machine Learning </title>
        <link>https://genstud.netlify.app/p/data-preprocessing-for-machine-learning/</link>
        <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
        
        <guid>https://genstud.netlify.app/p/data-preprocessing-for-machine-learning/</guid>
        <description>&lt;img src="https://genstud.netlify.app/p/data-preprocessing-for-machine-learning/pexels-squeeb-creative.jpg" alt="Featured image of post Data Preprocessing for Machine Learning " /&gt;
&lt;script src=&#34;https://genstud.netlify.app/p/data-preprocessing-for-machine-learning/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post is based on the &lt;a href=&#34;https://www.udemy.com/course/machinelearning/&#34;&gt;Machine Learning A-Z™: Hands-on Python &amp;amp; R In Data Science&lt;/a&gt; course on Udemy that i’m taking.
It’s a general introduction to the most used and known machine learning algorithms. This is the first chapter and a non-negotiable step not only for machine learning but also for every data analysis.&lt;/p&gt;
&lt;p&gt;This’ll be a blend of concepts introduced in the course and other personal considerations to make it more complete. There few general steps to take into account&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Understanding which variables are dependent and independent&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Load the data and ponder whether you should impute or remove missing data&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Encode categorical variables miss interpreted by R and re-encode them as binary&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Splitting dataset into training and test set&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Feature Scaling with Standardization or Normalization&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First of all, let’s import the data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset1
      Country Age Salary Purchased
   1   France  44  72000        No
   2    Spain  27  48000       Yes
   3  Germany  30  54000        No
   4    Spain  38  61000        No
   5  Germany  40     NA       Yes
   6   France  35  58000       Yes
   7    Spain  NA  52000        No
   8   France  48  79000       Yes
   9  Germany  50  83000        No
   10  France  37  67000       Yes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, there’s no way to proceed forward with any machine learning model if no dependent and independent variables are identified.&lt;/p&gt;
&lt;p&gt;There shouldn’t be the need to explain this but what we’re trying to do is to find a relationship between the independent variable and the dependent variable so that we can observe how one can influence the other.&lt;/p&gt;
&lt;p&gt;Sometimes it’s pretty clear who’s dependent and who’s independent, but many times it takes a bit of prior knowledge/thinking to correctly identify who’s who.&lt;/p&gt;
&lt;p&gt;Also, and we’re talking more in-depth about that when we’re seeing regression models, not every independent variable has the same effect on the dependent, and their role needs to be assessed.&lt;/p&gt;
&lt;p&gt;Dealing with missing data can be a real pain in the ass. Though it’s a crucial step, too often it’s treated as “yo, delete missing values and go on” and that can ruin your analysis.&lt;/p&gt;
&lt;p&gt;Whether to impute or delete missing values it’s an intricated topic that requires a lot of critical thinking and it’s also highly case dependent.&lt;/p&gt;
&lt;p&gt;This removes all missing data (NAs).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset1 &amp;lt;- na.omit(dataset1)
dataset1
      Country Age Salary Purchased
   1   France  44  72000        No
   2    Spain  27  48000       Yes
   3  Germany  30  54000        No
   4    Spain  38  61000        No
   6   France  35  58000       Yes
   8   France  48  79000       Yes
   9  Germany  50  83000        No
   10  France  37  67000       Yes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s say that we’ve decided we’re going with data deletion, there’re a couple of general rules we have to take into account when doing it. Again, it’s highly dependent on your specific case but we can at least agree on something.&lt;/p&gt;
&lt;p&gt;The amount of data that’s missing should be as low as possible and the whole dataset should have enough observation. Unfortunately, there’re no clear guidelines on what’s the acceptable number of missing data related to the size of the dataset.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If a whole observation has missing data for every variable, we can take into consideration the removal of the observation (optimal if these missing observations represent a casual subgroup of the whole group).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If a variable has missing data for every observation, we can take into consideration the removal of the variable (not if the variable is fundamental for our analysis).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both methods should be pondered seriously and both suffer from the risk of inducing a &lt;strong&gt;Selection Bias&lt;/strong&gt;, ’cause we gotta understand the underlying mechanism that’s generated the missing values.&lt;/p&gt;
&lt;p&gt;If there’s a reason why those values are missing we could completely misdirect the analysis and unconsciously select a group that’s not representative of the whole population.&lt;/p&gt;
&lt;p&gt;If the missing values are randomly distributed, removing them might cause the loss of too much info and therefore might be safer to impute them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;md.pattern(dataset2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://genstud.netlify.app/p/data-preprocessing-for-machine-learning/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;     Country Purchased Age Salary  
   8       1         1   1      1 0
   1       1         1   1      0 1
   1       1         1   0      1 1
           0         0   1      1 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See what’s the pattern of missing data and then impute them&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tempData &amp;lt;- mice(dataset2,m=5,meth=&amp;#39;pmm&amp;#39;,seed=500)
completedData &amp;lt;- complete(tempData,1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can decide to impute data using the mean and &lt;code&gt;mice&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;If you decide imputing data is the road you wanna go with, next step it’s to assess how to impute data. For short, imputing means to substitute missing data with new alternatives that’re coherent/plausible, obtained from the dataset or external sources, or both.&lt;/p&gt;
&lt;p&gt;The idea is to reduce the distortion introduced by missing data to the lowest degree possible. Ofc they have their fair share of disadvantages, ’cause we are considering our imputed data as “true observations”. The underlying idea is to preserve statistical accuracy.&lt;/p&gt;
&lt;p&gt;There are different ways to impute data, and all have to be considered based on the internal characteristics of the dataset, but we can summarize them as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Imputing the mean (reduces internal variance)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Imputing the median&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hot deck imputation&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Imputation through EM (expectation-maximization)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another useful way to do it is through the function &lt;code&gt;ifelse&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset3$Age = ifelse(is.na(dataset3$Age),
                     ave(dataset3$Age, FUN = function(x) mean(x, na.rm = TRUE)),
                     dataset3$Age)
dataset3$Salary = ifelse(is.na(dataset3$Salary),
                     ave(dataset3$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
                     dataset3$Salary)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another thing we gotta keep in mind is that R most of the time misinterprets the class of some data and it needs to be fixed.&lt;/p&gt;
&lt;p&gt;To do so, we need to convert categorical data that’s been interpreted as numeric to factor, and encode strings of characters to numbers to be able to feed them to machine learning algorithms.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset3$Country = factor(dataset3$Country,
                         levels = c(&amp;#39;France&amp;#39;, &amp;#39;Spain&amp;#39;, &amp;#39;Germany&amp;#39;),
                         labels = c(1, 2, 3))
dataset3
      Country      Age   Salary Purchased
   1        1 44.00000 72000.00        No
   2        2 27.00000 48000.00       Yes
   3        3 30.00000 54000.00        No
   4        2 38.00000 61000.00        No
   5        3 40.00000 63777.78       Yes
   6        1 35.00000 58000.00       Yes
   7        2 38.77778 52000.00        No
   8        1 48.00000 79000.00       Yes
   9        3 50.00000 83000.00        No
   10       1 37.00000 67000.00       Yes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s time to split the data into training and test set, and we’re gonna use a package called &lt;code&gt;caTools&lt;/code&gt; that allows us to split the samples given a variable.&lt;/p&gt;
&lt;p&gt;We’re also setting a seed to allow reproducibility of results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
split = sample.split(dataset3$Salary, SplitRatio = 0.8)
training_set = subset(dataset3, split == TRUE)
test_set = subset(dataset3, split == FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Usually, a good split ratio is around 75/80 % allowing for enough data to train the model and enough data to test it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;training_set = scale(training_set)
test_set = scale(test_set)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Feature scaling is usually done when two variables are not on the same scale and therefore is impossible to predict values. This happens because one variable completely dominates the other.&lt;/p&gt;
&lt;p&gt;Some packages by default apply a scaling factor (through Standardization or Normalization).
If feature scaling is needed, this will do the trick.&lt;/p&gt;
&lt;p&gt;That was it, a quick intro to data preprocessing for machine learning algorithms.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;carbon.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Carbon Code&lt;/p&gt;
&lt;/div&gt;
</description>
        </item>
        <item>
        <title>Genomic Data Science</title>
        <link>https://genstud.netlify.app/p/genomic-data-science/</link>
        <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
        
        <guid>https://genstud.netlify.app/p/genomic-data-science/</guid>
        <description>&lt;img src="https://genstud.netlify.app/p/genomic-data-science/pexels-madison-inouye-1831234.jpg" alt="Featured image of post Genomic Data Science" /&gt;&lt;h1 id=&#34;first-of-all-whats-this&#34;&gt;First of all, What&amp;rsquo;s this?&lt;/h1&gt;
&lt;p&gt;This is the program I&amp;rsquo;m enrolled in atm and as of today it&amp;rsquo;s still named  &amp;ldquo;Secondary Level Master&amp;rsquo;s Degree&amp;rdquo;.
Wait, let&amp;rsquo;s cut the chase right out, the heck is this?
For all the non-Italians out there, this needs a bit of an explanation and context. To be completely honest, I&amp;rsquo;m not aware if something similar even exists outside of this country.&lt;/p&gt;
&lt;p&gt;Anyways, Italian&amp;rsquo;s higher education is roughly structured as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Bachelor&amp;rsquo;s degree (3 years)&lt;/li&gt;
&lt;li&gt;Master&amp;rsquo;s degree( 2 years)&lt;/li&gt;
&lt;li&gt;Full-on 5/6 years degrees (like medicine or law, for example)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is considered as a &amp;ldquo;first-level&amp;rdquo;, or something like that, it&amp;rsquo;s quite foggy though. After this, you can take on one of these paths:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;PhD&lt;/li&gt;
&lt;li&gt;School of specialization&lt;/li&gt;
&lt;li&gt;First level Master&amp;rsquo;s degree&lt;/li&gt;
&lt;li&gt;Second level Master&amp;rsquo;s degree&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And here is where it gets tricky &amp;lsquo;cause these degrees have the same exact name as the Master that follows a bachelor.
To make this as simple as possible, a first-level Master&amp;rsquo;s degree is a Master that can be attended by bachelor students (undergrads), while a second-level Master&amp;rsquo;s is a Master&amp;rsquo;s that can be attended by Master&amp;rsquo;s students (post-bachelor, grad student).&lt;/p&gt;
&lt;p&gt;I know this is hella confusing but bear with me for a second. The idea underlying this structure is that these first/second-level Masters should bridge the gap between Universities and companies, giving the possibility to students to specialize in a sector and also gain work experience while doing it. Then what are schools of specialization, you might ask. Honestly, I have no clues.&lt;/p&gt;
&lt;h2 id=&#34;whats-the-structure-like&#34;&gt;What&amp;rsquo;s the Structure Like&lt;/h2&gt;
&lt;p&gt;How&amp;rsquo;s structured then? Well, it blends courses/modules and independent study spread over two years. It&amp;rsquo;s not as grade-centric as BSc or MSc are, but it does test you. In these two years, you&amp;rsquo;re also expected to do an internship on a subject that&amp;rsquo;s specific to the course, and the ultimate goal, in my case, is to produce a relevant thesis and hopefully a decent publication.&lt;/p&gt;
&lt;p&gt;It has 5 modules per year for two years plus some conferences and seminars throughout the whole year. Those will be more field-specific and organized within the student&amp;rsquo;s interests.&lt;/p&gt;
&lt;h2 id=&#34;modules-and-courses&#34;&gt;Modules and Courses&lt;/h2&gt;
&lt;p&gt;As said before, it&amp;rsquo;s divided into 5 modules per year and this&amp;rsquo;s a brief overview of the modules.&lt;/p&gt;
&lt;h3 id=&#34;first-year&#34;&gt;First year&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Statistics with R. Ofc starts off with an introduction of classical statistical inference (parametric and non-parametric statistics), data visualization in R, and a general introduction to R programming language and RStudio.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regression Models. It comprises linear and logistic regression, linear mixed models, and survival analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Resampling Methods. Covers a variety of topics like permutation/bootstrapping and randomization, Monte Carlo simulation, FDR, and empirical p-values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Epidemiology Applied to Genetics. Covers the design and the interpretation of various epidemiological studies.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Statistics applied to Genetics. It&amp;rsquo;s all about them Genome-Wide (GW) studies.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;second-year&#34;&gt;Second year&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Handling and Analysis of Big Data. Cloud and parallel computing,  use of databases (SQL and NoSQL), and introduction to Python programming.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bioinformatics Applied to Genetics. I&amp;rsquo;m so waiting for this. Next-gen seq, DNA/RNA-seq, variant calling, and Differential expression analyses.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Statistics Applied to Genomics. Lasso and elastic-net regression, dimensionality reduction, path and heredity analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;POST-GWAS. This also looks quite interesting, ranging from polygenic risk score and cross-validation, Meta-analysis of GWA studies to Mendelian randomization and method of Omics integrations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Machine Learning. This covers supervised/unsupervised/deep learning applied to genomics.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;what-am-i-expecting-out-of-this-degree&#34;&gt;What Am I Expecting Out of This Degree?&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s close this off by looking at what&amp;rsquo;s ahead. What will I get out of this program? Well, too early to tell but if I were to guess, I&amp;rsquo;d say that at least I should be a statistical ninja. Hope&amp;rsquo;s that statistical skills will be sound and crystal clear. Also, I do think that statistics involves a lot of critical thinking and pragmatic decision-making, and we don&amp;rsquo;t ever have enough of that, to be honest. Too much no sense interpretation of data happens in many fields, almost as if they were just made on the spot, so we better off without all of that.
I can&amp;rsquo;t really tell what will happen during this time, I only know that it&amp;rsquo;ll be fun.&lt;/p&gt;
&lt;p&gt;And yeah, someone please give me a job, it&amp;rsquo;s all fun and games until I can no longer pay for my snacks. Boy&amp;rsquo;s hungry, boy gotta eat.&lt;/p&gt;
&lt;p&gt;See ya.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>What a Year Ahead</title>
        <link>https://genstud.netlify.app/p/what-a-year-ahead/</link>
        <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
        
        <guid>https://genstud.netlify.app/p/what-a-year-ahead/</guid>
        <description>&lt;img src="https://genstud.netlify.app/p/what-a-year-ahead/zaksheuskaya.jpg" alt="Featured image of post What a Year Ahead" /&gt;&lt;p&gt;Although it may seem that I&amp;rsquo;m referring to the current COVID-19 situation, this is actually a post on how I&amp;rsquo;ve decided to ruin my life once and for all, with everything I&amp;rsquo;d like to know by the end of the year. Seems like a heck of a long shot now that I&amp;rsquo;m reading this again, but let this boy dream. Below some stuff I&amp;rsquo;m studying now and something that&amp;rsquo;s planned for the future.&lt;/p&gt;
&lt;h1 id=&#34;hit-em-with-the-nested-list&#34;&gt;Hit &amp;lsquo;em with the Nested List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Courses I&amp;rsquo;m currently taking
&lt;ul&gt;
&lt;li&gt;Genomic Data Science&lt;/li&gt;
&lt;li&gt;R for Data Science&lt;/li&gt;
&lt;li&gt;Machine Learning A-Z™: Hands-on Python &amp;amp; R In Data Science&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Courses I&amp;rsquo;ve planned
&lt;ul&gt;
&lt;li&gt;Single Cell RNA-seq Data Analysis&lt;/li&gt;
&lt;li&gt;Data Visualization &amp;amp; Dashboarding with R&lt;/li&gt;
&lt;li&gt;Statistics for Genomic Data Science&lt;/li&gt;
&lt;li&gt;Statistical Inference and Modeling for High-throughput Experiments&lt;/li&gt;
&lt;li&gt;High dimensional Data Analysis&lt;/li&gt;
&lt;li&gt;Case Studies in Functional Genomics&lt;/li&gt;
&lt;li&gt;HarvardX Biomedical Data Science Open Online Training&lt;/li&gt;
&lt;li&gt;SQL for data science&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;whats-cooking&#34;&gt;What&amp;rsquo;s cooking?&lt;/h2&gt;
&lt;p&gt;These are courses I&amp;rsquo;ve chosen to start with, two of them are actually thought through and well planned. Third one&amp;rsquo;s just an impulse and probably the least needed at this point (aka the ML one). But what can you do when your brain goes rouge and decides on its own, if not following it?&lt;/p&gt;
&lt;h3 id=&#34;genomic-data-science&#34;&gt;Genomic Data Science&lt;/h3&gt;
&lt;p&gt;I won&amp;rsquo;t redirect to the website of the Master&amp;rsquo;s program simply &amp;lsquo;cause it&amp;rsquo;s only in Italian and I don&amp;rsquo;t think will be that helpful, unless you wanna see google translate fail miserably. Also, I won&amp;rsquo;t get into much detail here because I have a post coming out exactly on this topic, not because I&amp;rsquo;m lazy.  It&amp;rsquo;s a two years commitment just like any other master, nothing fancy, lots of statistics. Various modules and courses that can hint you what it means to be a data scientist working on genomics, ranging from regression models and genomic epidemiology to statistics for genomics and bioinformatics applied to big data. Oh yeah, and a never-ending internship that&amp;rsquo;ll make you regret your life&amp;rsquo;s choices.&lt;/p&gt;
&lt;h3 id=&#34;r-for-data-sciencehttpsr4dshadconzindexhtml&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://r4ds.had.co.nz/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;R for Data Science&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Probably one of the most complete resources on the &amp;ldquo;basics&amp;rdquo; of R for data science and by far the most cited resource to start with data science in R that I&amp;rsquo;ve found. If you want a hard copy, help yourself &lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/R-Data-Science-Hadley-Wickham/dp/1491910399/ref=as_li_ss_tl?ie=UTF8&amp;amp;qid=1469550189&amp;amp;sr=8-1&amp;amp;keywords=R&amp;#43;for&amp;#43;data&amp;#43;science&amp;amp;linkCode=sl1&amp;amp;tag=devtools-20&amp;amp;linkId=6fe0069f9605cf847ed96c191f4e84dd&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;here&lt;/a&gt;.  And basics&amp;rsquo; s in quotes for a reason and I&amp;rsquo;ll get back to that in a second.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s structured like this: it throws you directly into the visualization/data manipulation/exploratory data analysis world, without knowing anything about programming; and then teaches you about the fundamentals of data wrangling (data import, tidying, strings, and factors), programming (functions, vectors, iterations and so on) and modeling.
Now, while I do believe the modeling part should be taught at the very end, I wonder why the core programming is taught later in the book. I was confused at the beginning, especially when manipulating data with dyplr, and I know some stuff about R.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m picturing someone approaching this for the very first time going like &amp;ldquo;the heck is this? Seriously, at some point was really hard to follow along even knowing the syntax, I can only imagine the struggle a complete newbie has to go through.
That&amp;rsquo;s why I&amp;rsquo;ve placed basics in quotes at the beginning, while some parts are really toddler material, this is actually a bit more complex than other introductions to R that you can find online (IMO). I found out that when we start using flights data frame (classic data frame used in data science for teaching) my brain cells just crumble and die.&lt;/p&gt;
&lt;p&gt;Besides this, I do think it&amp;rsquo;s a stupidly good book for learning data science and imma cherry-pick, from the chapters, what I suck at and work on it. But now that I think of it, I don&amp;rsquo;t think I can use &amp;ldquo;cherry-pick&amp;rdquo; for stuff  I&amp;rsquo;m bad at, right? But what if, you do enjoy slamming your face onto your keyboard and google searching every other minute? Is that cherry-picking stuff you suck at a positive behavior? The only way to get better at it? Am I losing my own thread here? I think so, let&amp;rsquo;s move on before it&amp;rsquo;s too late.&lt;/p&gt;
&lt;h3 id=&#34;machine-learning-a-z-hands-on-python--r-in-data-sciencehttpswwwudemycomcoursemachinelearning&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.udemy.com/course/machinelearning/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Machine Learning A-Z™: Hands-on Python &amp;amp; R In Data Science&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;ll be brutally honest with ya, this was utterly unnecessary at this point, but I was so goddam intrigued. Be it because ML is everywhere if you open up Twitter; every other post in data science threads is some random 13 years old that&amp;rsquo;s teaching ML to grownups &amp;lsquo;cause he&amp;rsquo;s already figured out between recesses, what he wants to do with his own life, while I&amp;rsquo;m there, not sure what I&amp;rsquo;ll cook for dinner. Seriously, it&amp;rsquo;s everywhere. Dunno, why I haven&amp;rsquo;t started this before (no wait I know, I think it&amp;rsquo;s called lacking foundations).&lt;/p&gt;
&lt;p&gt;Anyway, now that I pretty much know what&amp;rsquo;s going on in R, I thought this would be the perfect time to dive deep into the subject. I was particularly interested in what&amp;rsquo;s happening under the hood, mostly because R makes super easy running algorithms, thus I just can&amp;rsquo;t go running around and pressing buttons hoping to get something out. Apparently, you gotta understand what you&amp;rsquo;re doing.&lt;/p&gt;
&lt;p&gt;The course is structured so you can use both R and Python and tries to give you a foundation on the most used algos for machine learning. It&amp;rsquo;s something like &amp;ldquo;here are your toys, now figure how what you like and how to use them&amp;rdquo;. But we&amp;rsquo;ll talk about this a lot in future posts.&lt;/p&gt;
&lt;h2 id=&#34;courses-im-taking-this-year&#34;&gt;Courses I&amp;rsquo;m taking this year&lt;/h2&gt;
&lt;p&gt;The following are courses I&amp;rsquo;m planning on taking in the next few months. The underlying idea is to mix things up and integrate more field-specific courses with others that are broader and focus more on data science per se. This is what I came up with for now and hopefully, I&amp;rsquo;ll be able to get them done by the end of the year&lt;/p&gt;
&lt;h3 id=&#34;single-cell-rna-seq-data-analysis-with-r-offered-by-cschttpswwwcscfiwebtraining-scrnaseq&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.csc.fi/web/training/-/scrnaseq&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Single Cell RNA-seq Data Analysis with R offered by CSC&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;First one up on the list is, without any shadow of a doubt, scRNA-seq analysis (single-cell RNA sequencing). The course is sponsored by elixir &lt;a class=&#34;link&#34; href=&#34;https://elixir-europe.org/about-us/how-funded/eu-projects/excelerate&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;EXCELERATE&lt;/a&gt; program and organized by the Finnish company &lt;a class=&#34;link&#34; href=&#34;https://www.csc.fi/en/training&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CSC&lt;/a&gt;. The course is structured with video lessons that can be found on their &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=BfxDfL1GBzk&amp;amp;list=PLjiXAZO27elC_xnk7gVNM85I2IQl5BEJN&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;youtube channel&lt;/a&gt;, slides, and exercise notebooks on &lt;a class=&#34;link&#34; href=&#34;https://github.com/NBISweden/excelerate-scRNAseq&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Long story short, the course starts with data quality and preprocessing, normalization, confounding removal, and data integration. Then it focuses on dimensionality reduction, clustering, DGEA (Differential Gene Expression Analysis) and ends with cell-type identification, trajectories/Pseudo-time and spatial transcriptomics.
Even though high-dimensional data concepts are being explained throughout the course, better integration is required. Thus, the courses on edX and Coursera are just about that.&lt;/p&gt;
&lt;h3 id=&#34;data-visualization--dashboarding-with-r-on-courserahttpswwwcourseraorgspecializationsjhu-data-visualization-dashboarding-with-r&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.coursera.org/specializations/jhu-data-visualization-dashboarding-with-r&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Data Visualization &amp;amp; Dashboarding with R on Coursera&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A bit more of a general-purpose compilation of courses of data visualization. I&amp;rsquo;m skipping quite a bit here &amp;lsquo;cause it repeats a lot of the basics and hopefully, at this point I&amp;rsquo;m decent enough with R. First course is all about importing, tidying data and there&amp;rsquo;s a lot of info on reporting with R Markdown, and that&amp;rsquo;s why I&amp;rsquo;ve chosen this course, mainly.&lt;br&gt;
Second course&amp;rsquo;s main topic is ggplot2, of course. Cant&amp;rsquo; go wrong with that guy. I&amp;rsquo;ll quickly browse through this again, but most of the work it&amp;rsquo;s already done in &amp;ldquo;R for Data Science&amp;rdquo;.&lt;br&gt;
Third course&amp;rsquo;s the previous one but on steroids.&lt;br&gt;
Lastly, the fourth one, is all about publishing visualizations with Shiny and Flexdashboard. We going fancy fam.&lt;/p&gt;
&lt;h3 id=&#34;statistics-for-genomic-data-science-on-courserahttpswwwcourseraorglearnstatistical-genomicsspecializationgenomic-data-science&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.coursera.org/learn/statistical-genomics?specialization=genomic-data-science&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Statistics for Genomic Data Science on Coursera&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is a course that I&amp;rsquo;d consider borderline between field-specific biology and multi-purpose statistics. The reason is that, through the course, most of the statistics that are being taught are pretty much all the time applied to genomics and are case-specific. I&amp;rsquo;ll take this hoping that it&amp;rsquo;d cement my knowledge on exploratory data analysis, normalization, preprocessing, clustering and modeling for genomics.&lt;br&gt;
Also, in the last module they give you common pipelines for RNA/ChiP-seq, DNA methylation studies, and GWAS. Who am I to refuse this?&lt;/p&gt;
&lt;h3 id=&#34;statistical-inference-and-modeling-for-high-throughput-experiments-on-edxhttpswwwedxorgcoursestatistical-inference-and-modeling-for-high-throug&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.edx.org/course/statistical-inference-and-modeling-for-high-throug&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Statistical Inference and Modeling for High-throughput Experiments on edX&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This definitely will be the hardest one, mostly &amp;lsquo;cause of statistics overload. It&amp;rsquo;ll either bend me or break me, and there&amp;rsquo;s no going back. This is my public statement of commitment. The course focuses on a variety of statistical topics, ranging from multiple testing, error rate controls, false discovery rates to statistical modeling and Bayesian statistics.&lt;br&gt;
I know, from the very beginning, that this will cause a stupid amount of pain, but what really hurts is that, deep down, I know that I need this. You can&amp;rsquo;t run around the Genomics playground making your own statistics up. You gotta learn this. I gotta learn this. So, off I go, I guess.&lt;/p&gt;
&lt;h3 id=&#34;high-dimensional-data-analysis-on-edxhttpswwwedxorgcoursehigh-dimensional-data-analysis&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.edx.org/course/high-dimensional-data-analysis&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;High dimensional Data Analysis on edX&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is the first integration to the scRNA-seq course from CSC and provided by HarvardX on the &lt;a class=&#34;link&#34; href=&#34;https://www.edx.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;edX&lt;/a&gt; platform. This course revolves around concepts like mathematical distance, dimensionality reduction, singular value decomposition (SVC), and principal component analysis(PCA).&lt;br&gt;
Other modules that I find appealing are how to deal with batch effects, heatmaps and clustering, while I&amp;rsquo;m probably dropping the intro to machine learning also provided by them. I have nothing funny to say about this, sorry.&lt;/p&gt;
&lt;h3 id=&#34;case-studies-in-functional-genomics-on-edxhttpswwwedxorgcoursecase-studies-in-functional-genomicsindexproductqueryided6c49ffde7ddfe8c8787c6239463e95position1&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.edx.org/course/case-studies-in-functional-genomics?index=product&amp;amp;queryID=ed6c49ffde7ddfe8c8787c6239463e95&amp;amp;position=1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Case Studies in Functional Genomics on edX&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;ll probably take this one at the same time as the High Dimensional Data analysis, giving the fact this is focusing especially on the analysis of RNA-seq, DNA methylation and ChiP-seq data. Also, it&amp;rsquo;s gonna give a basic understanding of how reads are being mapped to the reference genome and how to assess the quality of NextGen data.&lt;br&gt;
Basically, NextGen data will become your best friend.&lt;/p&gt;
&lt;h3 id=&#34;harvardx-biomedical-data-science-open-online-traininghttprafalabgithubiopagesharvardxhtml&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;http://rafalab.github.io/pages/harvardx.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HarvardX Biomedical Data Science Open Online Training&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;m gonna make this quick, there&amp;rsquo;s this GitHub repo that&amp;rsquo;s been made from this book, &lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Data-Analysis-Life-Sciences-R/dp/1498775675/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1500332088&amp;amp;sr=1-1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;hard copy here&lt;/a&gt;, or maybe is the other way around, and it&amp;rsquo;s divided into three sections: &lt;a class=&#34;link&#34; href=&#34;http://rafalab.github.io/pages/harvardx.html#series_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Data Analysis for the Life Sciences&lt;/a&gt;, &lt;a class=&#34;link&#34; href=&#34;http://rafalab.github.io/pages/harvardx.html#series_2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Genomics Data Analysis&lt;/a&gt; and &lt;a class=&#34;link&#34; href=&#34;http://rafalab.github.io/pages/harvardx.html#python&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Using Python for Research&lt;/a&gt;.&lt;br&gt;
While the Python section is a hard pass (even though at some point I gotta learn that sneaky little brat), the others look super interesting even if they&amp;rsquo;re most likely repeating some stuff. As a general integration to the other courses, they seem appropriate.&lt;/p&gt;
&lt;h3 id=&#34;sql-for-data-science-on-courserahttpswwwcourseraorglearnsql-for-data-sciencespecializationlearn-sql-basics-data-science&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.coursera.org/learn/sql-for-data-science?specialization=learn-sql-basics-data-science&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SQL for data science on Coursera&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Well, there&amp;rsquo;s not much to say here, you can&amp;rsquo;t work in any data science-related field without knowing a wee bit of SQL.&lt;/p&gt;
&lt;p&gt;This is it, lots of stuff, not much time, way less determination. Let&amp;rsquo;s see what the future holds.&lt;/p&gt;
&lt;p&gt;See ya.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Setting Up The Blog</title>
        <link>https://genstud.netlify.app/p/new-test-for-post/</link>
        <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
        
        <guid>https://genstud.netlify.app/p/new-test-for-post/</guid>
        <description>&lt;img src="https://genstud.netlify.app/p/new-test-for-post/pawel-czerwinski-8uZPynIu-rQ-unsplash.jpg" alt="Featured image of post Setting Up The Blog" /&gt;&lt;p&gt;All right, let&amp;rsquo;s cut to the chase, creating this Blog with RStudio, blogdown, and Hugo themes after just a week of introduction to R programming for my MSc&amp;rsquo;s program, was hella hard and a pain in the butt. I&amp;rsquo;m not gonna lie.&lt;/p&gt;
&lt;p&gt;Most of the tutorials/how-to that you can find online, be it on video format or another person&amp;rsquo;s blog, are absolutely great; for them and for their settings and probably won&amp;rsquo;t transfer as well as you might think in your specific case. There&amp;rsquo;s always some troubleshooting you gotta do that&amp;rsquo;s not covered anywhere and you might need to come up with something on your own, merging together tips from others. I&amp;rsquo;m not saying it&amp;rsquo;s impossible of course, but I was surprised to see how hard and sometimes no sense (at least for now, I&amp;rsquo;ll probably get better in the future) it is.&lt;/p&gt;
&lt;p&gt;Even with blogdown and Hugo, which should be the no-brainer-JavaScript-HTML-free way of making a blog, was hard af. I&amp;rsquo;d chosen a different theme to start with but had to drop it after not being able to troubleshoot a deploying problem.&lt;/p&gt;
&lt;p&gt;Enough with the rant, let&amp;rsquo;s spread some positive vibes, shall we?&lt;/p&gt;
&lt;h1 id=&#34;relevant-resources&#34;&gt;Relevant Resources&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/a-data-analysts-guide-to-creating-your-personal-website-with-r-f0079ba9b81c&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Main Article from Bobby Muljono (towards data science)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/@aklson_DS/how-to-properly-setup-your-github-repository-mac-version-3a8047b899e5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Setting up GitHub repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://themes.gohugo.io/hugo-theme-stack/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugo Stack Theme&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All the relevant references are here, but you are most likely to do some good ol&#39; googling, to find out everything you need.&lt;/p&gt;
&lt;p&gt;TL;DR you create a new repo on RStudio with blogdown where you choose your theme, create a repo on GitHub that will be integrated with Git, modify your theme (this is the hardest part btw, but you&amp;rsquo;ll get better once you get used to it) and finally, you need a platform that deploys your website and hosts it (in my case I&amp;rsquo;ve used Netlify, that takes your files in your GitHub repo and turns it into what you are seeing now).&lt;/p&gt;
&lt;p&gt;Though the process is quite straightforward, once you get to the personalization of your website, that&amp;rsquo;s when it gets tricky. There should be, and that&amp;rsquo;s not always the case, so keep that in mind, documentation for every Hugo theme you decide to use and general documentation on the architecture of Hugo and the syntax. Basically, documents that explain how Hugo thinks. And, that&amp;rsquo;s as crucial as it gets. Once you&amp;rsquo;ve entered that rabbit hole, all you gotta do is figure out through trial and error what goes where, and when the blog throws a tantrum because that goddamn image is not in the right folder.&lt;/p&gt;
&lt;p&gt;If you are like me and have absolutely zero coding/computer science background, sometimes the terminology used makes no sense whatsoever and the only way out is to bang your head against a wall multiple times before getting to that &amp;ldquo;oh god, thanks it worked&amp;rdquo; moment. Last tip i can give you is to look at the examples provided , build the server on local host and tweak them as much as you can. That will hint you what you can and cannot do in order to manipulate the layout of the blog.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s it, this was mostly a general test for me, about the blog and the text piece, which was a lot harder than I thought it would. Juicier things are coming about coursers imma about to take and report here, and a general overview of the Msc program I&amp;rsquo;m currently in.&lt;/p&gt;
&lt;p&gt;I know this might sound super easy to professional webdevs and whatnot, but we not that good alright? So, if you were able to get through this&lt;/p&gt;
&lt;h1 id=&#34;heres-your-reward-my-dog-being-cute&#34;&gt;Here&amp;rsquo;s your reward. My dog being cute&lt;/h1&gt;
&lt;p&gt;&lt;figure style=&#34;flex-grow: 100; flex-basis: 240px&#34;&gt;
		&lt;a href=&#34;https://genstud.netlify.app/p/new-test-for-post/morris_dog.png&#34; data-size=&#34;3024x3024&#34;&gt;&lt;img src=&#34;https://genstud.netlify.app/p/new-test-for-post/morris_dog.png&#34;
				srcset=&#34;https://genstud.netlify.app/p/new-test-for-post/morris_dog_hu9463ed6ca25fadd516d86c8b0c57f3b5_14734430_480x0_resize_box_2.png 480w, https://genstud.netlify.app/p/new-test-for-post/morris_dog_hu9463ed6ca25fadd516d86c8b0c57f3b5_14734430_1024x0_resize_box_2.png 1024w&#34;
				width=&#34;3024&#34;
				height=&#34;3024&#34;
				loading=&#34;lazy&#34;
				alt=&#34;you thic ass boi&#34;&gt;
		&lt;/a&gt;
		
		&lt;figcaption&gt;you thic ass boi&lt;/figcaption&gt;
		
	&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;See ya!&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
